{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4668a2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg eBook of Frankenstein; Or, The Modern Prometheus\r\n",
      "    \r\n",
      "This ebook is for the use of anyone anywhere in the United States and\r\n",
      "most other parts of the world at no cost and with almost no restrictions\r\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\r\n",
      "of the Project Gutenberg License included with this ebook or online\r\n",
      "at www.gutenberg.org. If you are not located in the United States,\r\n",
      "you will have to check the laws of the country where you are locate\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# going to use URL for frankenstein\n",
    "book_url = \"https://www.gutenberg.org/cache/epub/84/pg84.txt\"\n",
    "response = requests.get(book_url)\n",
    "book_text = response.text\n",
    "\n",
    "print(book_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c16bdb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks after increasing chunk size: 447\n",
      "h delight. Do you understand this\r\n",
      "feeling? This breeze, which has travelled from the regions towards\r\n",
      "which I am advancing, gives me a foretaste of those icy climes.\r\n",
      "Inspirited by this wind of promise, my daydreams become more fervent\r\n",
      "and vivid. I try in vain to be persuaded that the pole is the seat of\r\n",
      "frost and desolation; it ever presents itself to my imagination as the\r\n",
      "region of beauty and delight. There, Margaret, the sun is for ever\r\n",
      "visible, its broad disk just skirting the horizon and diffusing a\r\n",
      "perpetual splendour. There—for with your leave, my sister, I will put\r\n",
      "some trust in preceding navigators—there snow and frost are banished;\r\n",
      "and, sailing over a calm sea, we may be wafted to a land surpassing in\r\n",
      "wonders and in beauty every region hitherto discovered on the habitable\r\n",
      "globe. Its productions and features may be without example, as the\r\n",
      "phenomena of the heavenly bodies undoubtedly are in those undiscovered\r\n",
      "solitudes. What may not be expected in a country of etern\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, chunk_size=1000):  # here we estbalish size of each chunk\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "text_chunks = chunk_text(book_text)\n",
    "\n",
    "print(f\"Number of chunks after increasing chunk size: {len(text_chunks)}\")\n",
    "print(text_chunks[2])  # Printing an example chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ff404b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from transformers import pipeline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# pre-trained model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35cde0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summaries generated: 30\n"
     ]
    }
   ],
   "source": [
    "summaries = []\n",
    "max_chunk_length = 1024 \n",
    "\n",
    "for chunk in text_chunks[:30]: #using 30 chunks, computationally difficult to go through 400+\n",
    "    \n",
    "    if len(chunk) > 0:  # Ensure the chunk is not empty\n",
    "        \n",
    "        # If the chunk is longer than max_chunk_length, split it into smaller parts\n",
    "        while len(chunk) > max_chunk_length:\n",
    "            \n",
    "            #  im using period as a split point that doesn't cut off sentences \n",
    "            \n",
    "            split_point = chunk.rfind('.', 0, max_chunk_length)  # Find the last period within limit\n",
    "            \n",
    "            if split_point == -1:  # split at max_chunk_length (assuming there was no period)\n",
    "                split_point = max_chunk_length\n",
    "\n",
    "            try:\n",
    "                #processing it here \n",
    "                summary = summarizer(chunk[:split_point], max_length=150, min_length=40, do_sample=False)\n",
    "                summaries.append(summary[0]['summary_text'])\n",
    "            except Exception as e:\n",
    "                print(f\"Error summarizing chunk: {e}\") #was for debugging\n",
    "            \n",
    "            # Continuing with the remainder of the chunk\n",
    "            chunk = chunk[split_point:]\n",
    "\n",
    "        # Process remaining part of the chunk\n",
    "        if len(chunk) > 0:\n",
    "            try:\n",
    "                summary = summarizer(chunk, max_length=150, min_length=40, do_sample=False)\n",
    "                summaries.append(summary[0]['summary_text'])\n",
    "            except Exception as e:\n",
    "                print(f\"Error summarizing chunk: {e}\")\n",
    "\n",
    "print(f\"Number of summaries generated: {len(summaries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a7a1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 Score: 0.3952110314132218\n",
      "Average ROUGE-2 Score: 0.34309992566916475\n",
      "Average ROUGE-L Score: 0.3583509549091607\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "rouge_scores = [scorer.score(text_chunks[i], summaries[i]) for i in range(len(summaries))]\n",
    "\n",
    "avg_rouge1 = sum([score['rouge1'].fmeasure for score in rouge_scores]) / len(rouge_scores)\n",
    "avg_rouge2 = sum([score['rouge2'].fmeasure for score in rouge_scores]) / len(rouge_scores)\n",
    "avg_rougeL = sum([score['rougeL'].fmeasure for score in rouge_scores]) / len(rouge_scores)\n",
    "\n",
    "print(f\"Average ROUGE-1 Score: {avg_rouge1}\")\n",
    "print(f\"Average ROUGE-2 Score: {avg_rouge2}\")\n",
    "print(f\"Average ROUGE-L Score: {avg_rougeL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7299f672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
